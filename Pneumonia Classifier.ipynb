{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85dc467a-5830-44c0-ab74-435be0e5593c",
   "metadata": {},
   "source": [
    "Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n",
    "\n",
    "By fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n",
    "\n",
    "## The Data\n",
    "\n",
    "<img src=\"x-rays_sample.png\" align=\"center\"/>\n",
    "&nbsp\n",
    "\n",
    "You have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n",
    "\n",
    "There are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f522b79-2a5a-4472-adb9-0d924870bfa1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3211,
    "lastExecutedAt": 1732458845271,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics",
    "outputsMetadata": {
     "0": {
      "height": 432,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
      "Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# # Make sure to run this cell to use torchmetrics.\n",
    "!pip install torch torchvision torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb1bedee-bcd5-4c80-a5ed-93df89af0295",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 55,
    "lastExecutedAt": 1732458845328,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# -------------------------\n",
    "# Data loading\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Train model\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Evaluate model\n",
    "from torchmetrics import Accuracy, F1Score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(101010)\n",
    "np.random.seed(101010)\n",
    "random.seed(101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd91680d-cb63-4876-9a51-4ee6bb250c7d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1732458845376,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzip the data folder\n",
    "if not os.path.exists('data/chestxrays'):\n",
    "    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1732458845428,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   },
   "outputs": [],
   "source": [
    "# Define the transformations to apply to the images for use with ResNet-18\n",
    "transform_mean = [0.485, 0.456, 0.406]\n",
    "transform_std =[0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n",
    "\n",
    "# Apply the image transforms\n",
    "train_dataset = ImageFolder('data/chestxrays/train', transform=transform)\n",
    "test_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c99cf95b-83f3-49e4-9777-4e70736452d8",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 197,
    "lastExecutedAt": 1732458845625,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n# Use as many cells as you need\nweights = models.ResNet18_Weights.DEFAULT\nresnet18 = models.resnet18(weights=weights)"
   },
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Use as many cells as you need\n",
    "weights = models.ResNet18_Weights.DEFAULT\n",
    "resnet18 = models.resnet18(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "546ac258-07f7-4855-9a1f-3b1a0588465e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1732458845676,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "for param in resnet18.parameters():\n    param.requires_grad = False"
   },
   "outputs": [],
   "source": [
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce775394-a2ff-4151-bb6b-30cafee8df71",
   "metadata": {},
   "source": [
    "Adjusting final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bdce8b4-94ad-448e-964a-7f249f7da19e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1732458845724,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "num_features = resnet18.fc.in_features\nprint(num_features)\n\nresnet18.fc = nn.Linear(num_features, 1)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "num_features = resnet18.fc.in_features\n",
    "print(num_features)\n",
    "\n",
    "resnet18.fc = nn.Linear(num_features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e0127-cc25-456e-bb47-51c17aa35154",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1efba1eb-9953-48ff-86c5-d8c6501a1428",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 66969,
    "lastExecutedAt": 1732458912693,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nresnet18 = resnet18.to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(resnet18.fc.parameters(), lr=0.01)\n\nnum_epochs = 3 #you can increase the number of epochs to improve accuracy\n\nfor epoch in range(num_epochs):\n    resnet18.train()\n    running_loss = 0.0\n    \n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.to(device), labels.to(device)\n        labels = labels.float().view(-1,1)\n        \n        # Zero the parameter gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = resnet18(inputs)\n        \n        # Compare between outputs and labels\n        loss = criterion(outputs, labels)\n        \n        # Backward pass, calculates gradients\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        # Accumulate running loss\n        running_loss += loss.item()\n        \n        if batch_idx % 10 == 0:\n            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {loss.item():.4f}\") \n    \n    # Average loss for the epoch\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss / len(train_loader):.4f}\")",
    "outputsMetadata": {
     "0": {
      "height": 122,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Batch [1], Loss: 0.7188\n",
      "Epoch [1/3], Average Loss: 1.3915\n",
      "Epoch [2/3], Batch [1], Loss: 1.0120\n",
      "Epoch [2/3], Average Loss: 0.8973\n",
      "Epoch [3/3], Batch [1], Loss: 1.1386\n",
      "Epoch [3/3], Average Loss: 0.9199\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3 #you can increase the number of epochs to improve accuracy\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    resnet18.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.float().view(-1,1)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = resnet18(inputs)\n",
    "        \n",
    "        # Compare between outputs and labels\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass, calculates gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate running loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}], Loss: {loss.item():.4f}\") \n",
    "    \n",
    "    # Average loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70761893-e66f-40fe-8862-dac9b18a13ab",
   "metadata": {},
   "source": [
    "### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 7096,
    "lastExecutedAt": 1732458919790,
    "lastExecutedByKernel": "3dffbb3d-7da0-414e-9f01-538fb3739fb2",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n    test_f1_score = f1_metric(all_preds, all_labels).item()\n    \n    print(f\"Test Accuracy: {test_acc:.3f}\")\n    print(f\"Test F1 Score: {test_f1:.3f}\")",
    "outputsMetadata": {
     "0": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.580\n",
      "Test F1 Score: 0.704\n"
     ]
    }
   ],
   "source": [
    "#-------------------\n",
    "# Evaluate the model\n",
    "#-------------------\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model = resnet18\n",
    "model.eval()\n",
    "\n",
    "# Initialize metrics for accuracy and F1 score\n",
    "accuracy_metric = Accuracy(task=\"binary\")\n",
    "f1_metric = F1Score(task=\"binary\")\n",
    "\n",
    "# Create lists store all predictions and labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "  for inputs, labels in test_loader:\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n",
    "\n",
    "    # Extend the lists with predictions and labels\n",
    "    all_preds.extend(preds.tolist())\n",
    "    all_labels.extend(labels.unsqueeze(1).tolist())\n",
    "\n",
    "    # Convert lists back to tensors\n",
    "    all_preds = torch.tensor(all_preds)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "\n",
    "    # Calculate accuracy and F1 score\n",
    "    test_accuracy = accuracy_metric(all_preds, all_labels).item()\n",
    "    test_f1_score = f1_metric(all_preds, all_labels).item()\n",
    "    \n",
    "    print(f\"Test Accuracy: {test_acc:.3f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
